ğŸ“˜ ChatWithWebsite â€” A Simple Offline Website Q&A Assistant

A fast, offline, lightweight chatbot that answers questions based on any website you provide â€” without needing Google API, OpenAI API, or embeddings.

This project lets users paste a website URL, extract the content, split it into readable chunks, and answer questions using a simple, offline keyword-based retrieval system.

It is designed for:

âœ” People with low RAM laptops (4GB)
âœ” No API keys
âœ” Zero costs
âœ” Very fast response time
âœ” Works entirely on your local machine using Streamlit

â­ Features
ğŸ”¹ 1. Paste Any Website URL

Load any publicly available webpage and extract its content automatically.

ğŸ”¹ 2. No API Keys Required

This version uses offline keyword-matching logic instead of Gemini/OpenAI embeddings, making it:

100% free

Private

Fast

Lightweight

ğŸ”¹ 3. Smart Chunking

Uses LangChainâ€™s RecursiveCharacterTextSplitter to chunk website text into meaningful pieces.

ğŸ”¹ 4. Ask Unlimited Questions

Each question is answered based on the chunk most related to your query.

ğŸ”¹ 5. Chat UI Built With Streamlit

A friendly dark-themed interface with chat bubbles.

ğŸ”¹ 6. Fully Offline Processing

No data is sent to any external server.

ğŸ–¼ App Preview
Homepage â€“ Enter Website URL
Chat Interface
ğŸ§  How It Works (Offline RAG Logic)

User enters website URL

Website content is loaded using WebBaseLoader

Text is split into chunks (1500 characters each)

For each question:

We check which chunk contains the most matching keywords

That chunk is returned as the answer

Chat history is saved inside st.session_state

âœ” No Embeddings
âœ” No Vector Databases
âœ” No AI API Keys
âœ” No Internet required after loading the website
ğŸ›  Tech Stack
Component	Technology
Frontend	Streamlit
Backend Logic	Python
Web Scraping	LangChain WebBaseLoader
Text Processing	LangChain Text Splitter
State Management	Streamlit Session State
OS	Windows / Mac / Linux
ğŸ“‚ Project Folder Structure
ChatWithWebsite/
â”‚
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ app.py
â”‚   â””â”€â”€ requirements.txt (optional)
â”‚
â”œâ”€â”€ .gitignore
â”œâ”€â”€ .env  (ignored)
â””â”€â”€ README.md

ğŸš€ Installation & Setup
1ï¸âƒ£ Clone the Repository
git clone https://github.com/ishapadhal/ChatWithWebsite.git
cd ChatWithWebsite/src

2ï¸âƒ£ Create Conda Environment
conda create -n chatweb python=3.10 -y
conda activate chatweb

3ï¸âƒ£ Install Dependencies
pip install streamlit langchain-community langchain-text-splitters

4ï¸âƒ£ Run the Application
streamlit run app.py

âœ” Local URL
http://localhost:8501

ğŸ’¬ Usage

Enter any website URL in the sidebar

Wait for the content to load

Ask any question related to the website

Get instant offline answers

Chat history stays until page refresh

ğŸ” Security

No API keys needed

No data sent to cloud servers

Everything runs on your laptop

ğŸ“˜ Code Overview
Load Website Text
loader = WebBaseLoader(url)
docs = loader.load()

Split Into Chunks
splitter = RecursiveCharacterTextSplitter(chunk_size=1500, chunk_overlap=200)
chunks = splitter.split_documents(docs)

Offline Question Answering
score = sum(word in text for word in question_words)

Streamlit Chat Interface
user_query = st.chat_input("Ask your question...")

ğŸ§© Future Improvements

Add real embeddings using sentence-transformers

Add Gemini/OpenAI support (optional)

Use ChromaDB for vector search

Add website screenshot preview

Add caching for faster load time

Add theme switch (dark/light mode)

Mobile responsive UI
<img width="1909" height="871" alt="Screenshot 2025-12-11 204308" src="https://github.com/user-attachments/assets/b892fd1e-c91a-4244-a598-c3e153a9c34b" />


â¤ï¸ Contributions

Pull requests are welcome!
If you have ideas to improve this, feel free to open an issue.

â­ If you like the project, give it a star!

It motivates me to improve it more.
